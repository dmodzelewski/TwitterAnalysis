{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import openpyxl\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:05.290966500Z",
     "start_time": "2023-05-04T13:14:05.286447200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "chat_words_str = \"\"\"\n",
    "DM=Direct message\n",
    "CT=Cuttweet\n",
    "RT=Retweet\n",
    "PRT=Partial retweet\n",
    "MT=Modified tweet\n",
    "PRT=Please retweet\n",
    "HT=Hat tip\n",
    "CC=Carbon-copy\n",
    "CX=Correction\n",
    "EM=Email Marketing\n",
    "SEO=Search Engine Optimization\n",
    "SROI=Social Return on Investment\n",
    "SN=Social Network\n",
    "YT=YouTube\n",
    "UGC=User-Generated Content\n",
    "SMO=Social Media Optimization\n",
    "FB=Facebook\n",
    "LI=LinkedIn\n",
    "SM=Social Media\n",
    "SMM=Social Media Marketing\n",
    "EZine=Electronic Magazine\n",
    "BGD=Background\n",
    "CD9=Code 9, parents are around\n",
    "BTW=By the way\n",
    "AB=About\n",
    "ABT=About\n",
    "DD=Dear daughter\n",
    "AFAIK=far as I know\n",
    "AYFKMWTS=Are you f—ing kidding me with this s—?\n",
    "BR=Best regards\n",
    "CHK=Check\n",
    "CUL8R=See you later\n",
    "DP=used to mean “profile pic”\n",
    "FML=F— my life\n",
    "FUBAR=F—ed up beyond all repair (slang from the US Military)\n",
    "BBFN=Bye for now\n",
    "B4=Before\n",
    "DS=Dear son\n",
    "FF=Follow Friday\n",
    "EMA=Email address\n",
    "DYK=Do you know\n",
    "F2F=Face to face\n",
    "FTF=Face to face\n",
    "HAGN=Have a good night\n",
    "DF=Dear fiancé\n",
    "DAM=Don’t annoy me\n",
    "FFS=For F—‘s Sake\n",
    "EM=Email\n",
    "EML=Email\n",
    "FOTD=Find of the day\n",
    "FTW=For the win, F— the world\n",
    "FWIW=For what it’s worth\n",
    "HTH=Hope that helps\n",
    "GMAFB=Give me a f—ing break\n",
    "HAND=Have a nice day\n",
    "ICYMI=In case you missed it\n",
    "GTFOOH=Get the f— out of here\n",
    "GTS=Guess the song\n",
    "HOTD=Headline of the day\n",
    "IIRC=If I remember correctly\n",
    "KYSO=Knock your socks off\n",
    "KK=Kewl kewl, or ok, got it\n",
    "HT=Head through\n",
    "IC=I see\n",
    "IDK=I don’t know\n",
    "LHH=hella hard\n",
    "ZOMG=OMG to the max\n",
    "IMHO=In my humble opinion\n",
    "NFW=No f—ing way\n",
    "ORLY=Oh, really?\n",
    "YOYO=You’re on your own\n",
    "LMAO=Laughing my ass off\n",
    "IRL=In real life\n",
    "JK=Just kidding\n",
    "JV=Joint venture\n",
    "LO=Little One\n",
    "LOL=Laugh out loud\n",
    "MM=Music Monday\n",
    "LMK=Let me know\n",
    "TY=Thank you\n",
    "SRS=Serious\n",
    "STF=Shut the f—\n",
    "STFU=Shut the f— up!\n",
    "TL=Timeline\n",
    "TYIA=Thank you in advance\n",
    "TT=Trending topic\n",
    "TYVW=Thank you very much\n",
    "BRB=Be Right Back\n",
    "AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "B4N=Bye For Now\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=ILU: I Love You\n",
    "IMHO=In My Honest Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laugh My A.. Off\n",
    "LOL=Laughing Out Loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "SFW=Safe for work\n",
    "TY=Thank you\n",
    "TMB=Tweet me back\n",
    "BRB=Be Right Back\n",
    "IMO=In My Opinion\n",
    "RLRT=Real-life re-tweet, a close cousin to OH\n",
    "OOMF=One of my friends/followers\n",
    "NTS=Note to self\n",
    "RTFM=Read the f—ing manual\n",
    "SNAFU=Situation normal, all f—ed up (slang from the US Military)\n",
    "RLRT=Real-life re-tweet, a close cousin to OH\n",
    "SMH=Shaking my head\n",
    "STFW=Search the f—ing web!\n",
    "TFTT=Thanks for this tweet\n",
    "SOB=Son of a B—-\n",
    "TFTF=Thanks for the follow\n",
    "PRW=Parents Are Watching\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:05.667679700Z",
     "start_time": "2023-05-04T13:14:05.654620200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"template.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:05.996657500Z",
     "start_time": "2023-05-04T13:14:05.982459100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:06.301678700Z",
     "start_time": "2023-05-04T13:14:06.286680200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chat Words Conversion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       text  \\\n0      The cars drive, fast and erratically   \n1                       the car drive slow?   \n2  The bike ride very fast and erratically!   \n\n                       text_chat_conversion  \n0      The cars drive, fast and erratically  \n1                       the car drive slow?  \n2  The bike ride very fast and erratically!  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_chat_conversion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The cars drive, fast and erratically</td>\n      <td>The cars drive, fast and erratically</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the car drive slow?</td>\n      <td>the car drive slow?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The bike ride very fast and erratically!</td>\n      <td>The bike ride very fast and erratically!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words_map_dict = {}\n",
    "chat_words_list = []\n",
    "for line in chat_words_str.split(\"\\n\"):\n",
    "    if line != \"\":\n",
    "        cw = line.split(\"=\")[0]\n",
    "        cw_expanded = line.split(\"=\")[1]\n",
    "        chat_words_list.append(cw)\n",
    "        chat_words_map_dict[cw] = cw_expanded\n",
    "chat_words_list = set(chat_words_list)\n",
    "\n",
    "\n",
    "def chat_words_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words_list:\n",
    "            new_text.append(chat_words_map_dict[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "\n",
    "df[\"text_chat_conversion\"] = df[\"text\"].apply(lambda text: chat_words_conversion(text))\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:06.629753Z",
     "start_time": "2023-05-04T13:14:06.614602500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spelling correction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       text  \\\n0      The cars drive, fast and erratically   \n1                       the car drive slow?   \n2  The bike ride very fast and erratically!   \n\n                       text_chat_conversion  \\\n0      The cars drive, fast and erratically   \n1                       the car drive slow?   \n2  The bike ride very fast and erratically!   \n\n                         correct_spellings  \n0      The cars drive fast and erratically  \n1                       the car drive slow  \n2  The bike ride very fast and erratically  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_chat_conversion</th>\n      <th>correct_spellings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The cars drive, fast and erratically</td>\n      <td>The cars drive, fast and erratically</td>\n      <td>The cars drive fast and erratically</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the car drive slow?</td>\n      <td>the car drive slow?</td>\n      <td>the car drive slow</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The bike ride very fast and erratically!</td>\n      <td>The bike ride very fast and erratically!</td>\n      <td>The bike ride very fast and erratically</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "\n",
    "df[\"correct_spellings\"] = df[\"text_chat_conversion\"].apply(lambda text: correct_spellings(text))\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:07.177307500Z",
     "start_time": "2023-05-04T13:14:06.947511900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:07.209340600Z",
     "start_time": "2023-05-04T13:14:07.181303800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Punctuation removal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       text  \\\n0      The cars drive, fast and erratically   \n1                       the car drive slow?   \n2  The bike ride very fast and erratically!   \n\n                       text_chat_conversion  \\\n0      The cars drive, fast and erratically   \n1                       the car drive slow?   \n2  The bike ride very fast and erratically!   \n\n                         correct_spellings  \\\n0      The cars drive fast and erratically   \n1                       the car drive slow   \n2  The bike ride very fast and erratically   \n\n                    text_punctation_remove  \\\n0      The cars drive fast and erratically   \n1                       the car drive slow   \n2  The bike ride very fast and erratically   \n\n                                text_lower  \n0      the cars drive fast and erratically  \n1                       the car drive slow  \n2  the bike ride very fast and erratically  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_chat_conversion</th>\n      <th>correct_spellings</th>\n      <th>text_punctation_remove</th>\n      <th>text_lower</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The cars drive, fast and erratically</td>\n      <td>The cars drive, fast and erratically</td>\n      <td>The cars drive fast and erratically</td>\n      <td>The cars drive fast and erratically</td>\n      <td>the cars drive fast and erratically</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the car drive slow?</td>\n      <td>the car drive slow?</td>\n      <td>the car drive slow</td>\n      <td>the car drive slow</td>\n      <td>the car drive slow</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The bike ride very fast and erratically!</td>\n      <td>The bike ride very fast and erratically!</td>\n      <td>The bike ride very fast and erratically</td>\n      <td>The bike ride very fast and erratically</td>\n      <td>the bike ride very fast and erratically</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "\n",
    "\n",
    "def remove_punctation(text):\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "\n",
    "df[\"text_punctation_remove\"] = df[\"text_chat_conversion\"].apply(lambda text: remove_punctation(text))\n",
    "df[\"text_lower\"] = df[\"text_punctation_remove\"].str.lower()\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:07.537665900Z",
     "start_time": "2023-05-04T13:14:07.460958900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stop Words removal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\", \".join(stopwords.words('english'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:07.834033600Z",
     "start_time": "2023-05-04T13:14:07.808810300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                           0  \\\ntext                    The cars drive, fast and erratically   \ntext_chat_conversion    The cars drive, fast and erratically   \ncorrect_spellings        The cars drive fast and erratically   \ntext_punctation_remove   The cars drive fast and erratically   \ntext_lower               the cars drive fast and erratically   \ntext_stopwords_removal           cars drive fast erratically   \n\n                                          1  \\\ntext                    the car drive slow?   \ntext_chat_conversion    the car drive slow?   \ncorrect_spellings        the car drive slow   \ntext_punctation_remove   the car drive slow   \ntext_lower               the car drive slow   \ntext_stopwords_removal       car drive slow   \n\n                                                               2  \ntext                    The bike ride very fast and erratically!  \ntext_chat_conversion    The bike ride very fast and erratically!  \ncorrect_spellings        The bike ride very fast and erratically  \ntext_punctation_remove   The bike ride very fast and erratically  \ntext_lower               the bike ride very fast and erratically  \ntext_stopwords_removal                bike ride fast erratically  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>text</th>\n      <td>The cars drive, fast and erratically</td>\n      <td>the car drive slow?</td>\n      <td>The bike ride very fast and erratically!</td>\n    </tr>\n    <tr>\n      <th>text_chat_conversion</th>\n      <td>The cars drive, fast and erratically</td>\n      <td>the car drive slow?</td>\n      <td>The bike ride very fast and erratically!</td>\n    </tr>\n    <tr>\n      <th>correct_spellings</th>\n      <td>The cars drive fast and erratically</td>\n      <td>the car drive slow</td>\n      <td>The bike ride very fast and erratically</td>\n    </tr>\n    <tr>\n      <th>text_punctation_remove</th>\n      <td>The cars drive fast and erratically</td>\n      <td>the car drive slow</td>\n      <td>The bike ride very fast and erratically</td>\n    </tr>\n    <tr>\n      <th>text_lower</th>\n      <td>the cars drive fast and erratically</td>\n      <td>the car drive slow</td>\n      <td>the bike ride very fast and erratically</td>\n    </tr>\n    <tr>\n      <th>text_stopwords_removal</th>\n      <td>cars drive fast erratically</td>\n      <td>car drive slow</td>\n      <td>bike ride fast erratically</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "\n",
    "df[\"text_stopwords_removal\"] = df[\"text_lower\"].apply(lambda text: remove_stopwords(text))\n",
    "df.T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:08.026288500Z",
     "start_time": "2023-05-04T13:14:07.994732900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Freq and rare words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# cnt = Counter()\n",
    "# for text in df[\"text_stopwords_removal\"].values:\n",
    "#     for word in text.split():\n",
    "#         cnt[word] += 1\n",
    "#\n",
    "# cnt.most_common(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:08.348045500Z",
     "start_time": "2023-05-04T13:14:08.343042300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "# def remove_freqwords(text):\n",
    "#     \"\"\"custom function to remove the frequent words\"\"\"\n",
    "#     return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
    "#\n",
    "# df[\"text_wo_stopfreq\"] = df[\"text_wo_stop\"].apply(lambda text: remove_freqwords(text))\n",
    "# df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:08.543818300Z",
     "start_time": "2023-05-04T13:14:08.537816800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# n_rare_words = 10\n",
    "# RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "# def remove_rarewords(text):\n",
    "#     \"\"\"custom function to remove the rare words\"\"\"\n",
    "#     return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
    "#\n",
    "# df[\"text_wo_stopfreqrare\"] = df[\"text_wo_stopfreq\"].apply(lambda text: remove_rarewords(text))\n",
    "# df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:08.730005900Z",
     "start_time": "2023-05-04T13:14:08.711005500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stemming"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Drop the two columns\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "\n",
    "df[\"text_stemmed\"] = df[\"text_stopwords_removal\"].apply(lambda text: stem_words(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:09.038304800Z",
     "start_time": "2023-05-04T13:14:09.036307200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "\n",
    "df[\"text_preprocessed\"] = df[\"text_stopwords_removal\"].apply(lambda text: lemmatize_words(text))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:09.245019300Z",
     "start_time": "2023-05-04T13:14:09.230022500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       text  \\\n0      The cars drive, fast and erratically   \n1                       the car drive slow?   \n2  The bike ride very fast and erratically!   \n\n                       text_chat_conversion  \\\n0      The cars drive, fast and erratically   \n1                       the car drive slow?   \n2  The bike ride very fast and erratically!   \n\n                         correct_spellings  \\\n0      The cars drive fast and erratically   \n1                       the car drive slow   \n2  The bike ride very fast and erratically   \n\n                    text_punctation_remove  \\\n0      The cars drive fast and erratically   \n1                       the car drive slow   \n2  The bike ride very fast and erratically   \n\n                                text_lower       text_stopwords_removal  \\\n0      the cars drive fast and erratically  cars drive fast erratically   \n1                       the car drive slow               car drive slow   \n2  the bike ride very fast and erratically   bike ride fast erratically   \n\n           text_stemmed           text_preprocessed  \\\n0  car drive fast errat  car drive fast erratically   \n1        car drive slow              car drive slow   \n2  bike ride fast errat  bike ride fast erratically   \n\n                  text_lemmatized_with_pos  \n0       The car drive fast and erratically  \n1                       the car drive slow  \n2  The bike ride very fast and erratically  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_chat_conversion</th>\n      <th>correct_spellings</th>\n      <th>text_punctation_remove</th>\n      <th>text_lower</th>\n      <th>text_stopwords_removal</th>\n      <th>text_stemmed</th>\n      <th>text_preprocessed</th>\n      <th>text_lemmatized_with_pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The cars drive, fast and erratically</td>\n      <td>The cars drive, fast and erratically</td>\n      <td>The cars drive fast and erratically</td>\n      <td>The cars drive fast and erratically</td>\n      <td>the cars drive fast and erratically</td>\n      <td>cars drive fast erratically</td>\n      <td>car drive fast errat</td>\n      <td>car drive fast erratically</td>\n      <td>The car drive fast and erratically</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the car drive slow?</td>\n      <td>the car drive slow?</td>\n      <td>the car drive slow</td>\n      <td>the car drive slow</td>\n      <td>the car drive slow</td>\n      <td>car drive slow</td>\n      <td>car drive slow</td>\n      <td>car drive slow</td>\n      <td>the car drive slow</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The bike ride very fast and erratically!</td>\n      <td>The bike ride very fast and erratically!</td>\n      <td>The bike ride very fast and erratically</td>\n      <td>The bike ride very fast and erratically</td>\n      <td>the bike ride very fast and erratically</td>\n      <td>bike ride fast erratically</td>\n      <td>bike ride fast errat</td>\n      <td>bike ride fast erratically</td>\n      <td>The bike ride very fast and erratically</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"J\": wordnet.ADJ, \"R\": wordnet.ADV}\n",
    "\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join(\n",
    "        [lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "\n",
    "df[\"text_lemmatized_with_pos\"] = df[\"correct_spellings\"].apply(lambda text: lemmatize_words(text))\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:09.487364500Z",
     "start_time": "2023-05-04T13:14:09.459366800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "## Emoji and emoticons removal/conversion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:09.674855300Z",
     "start_time": "2023-05-04T13:14:09.667852800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "# def remove_emoji(string):\n",
    "#     emoji_pattern = re.compile(\"[\"\n",
    "#                            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#                            u\"\\U00002702-\\U000027B0\"\n",
    "#                            u\"\\U000024C2-\\U0001F251\"\n",
    "#                            \"]+\", flags=re.UNICODE)\n",
    "#     return emoji_pattern.sub(r'', string)\n",
    "# df[\"text_no_emoji\"] = df[\"text_lemmatized_with_pos\"].apply(lambda text: remove_emoji(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:09.880360900Z",
     "start_time": "2023-05-04T13:14:09.848392900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "'Hello Happy_face_smiley Happy_face_smiley'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_emoticons(text):\n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'(' + emot + ')', \"_\".join(EMOTICONS[emot].replace(\",\", \"\").split()), text)\n",
    "    return text\n",
    "\n",
    "\n",
    "text = \"Hello :-) :-)\"\n",
    "convert_emoticons(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:10.306346100Z",
     "start_time": "2023-05-04T13:14:10.270292200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "#TODO EMOJI replace with pytyhon emoji library"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:11.043215200Z",
     "start_time": "2023-05-04T13:14:11.037699100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove urls and HTML"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:12.180405900Z",
     "start_time": "2023-05-04T13:14:12.176407700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:12.658590500Z",
     "start_time": "2023-05-04T13:14:12.653591Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenizacja"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "\n",
    "def tokenize_tweets(text):\n",
    "    return tweet_tokenizer.tokenize(text)\n",
    "\n",
    "df[\"text_tokenize\"] = df[\"text_chat_conversion\"].apply(lambda text: tokenize_tweets(text))\n",
    "df[\"text_tokenize_preprocessed\"] = df[\"text_preprocessed\"].apply(lambda text: tokenize_tweets(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:13.820553800Z",
     "start_time": "2023-05-04T13:14:13.801410500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                        0  \\\ntext                                 The cars drive, fast and erratically   \ntext_chat_conversion                 The cars drive, fast and erratically   \ncorrect_spellings                     The cars drive fast and erratically   \ntext_punctation_remove                The cars drive fast and erratically   \ntext_lower                            the cars drive fast and erratically   \ntext_stopwords_removal                        cars drive fast erratically   \ntext_stemmed                                         car drive fast errat   \ntext_preprocessed                              car drive fast erratically   \ntext_lemmatized_with_pos               The car drive fast and erratically   \ntext_tokenize               [The, cars, drive, ,, fast, and, erratically]   \ntext_tokenize_preprocessed                [car, drive, fast, erratically]   \n\n                                                     1  \\\ntext                               the car drive slow?   \ntext_chat_conversion               the car drive slow?   \ncorrect_spellings                   the car drive slow   \ntext_punctation_remove              the car drive slow   \ntext_lower                          the car drive slow   \ntext_stopwords_removal                  car drive slow   \ntext_stemmed                            car drive slow   \ntext_preprocessed                       car drive slow   \ntext_lemmatized_with_pos            the car drive slow   \ntext_tokenize               [the, car, drive, slow, ?]   \ntext_tokenize_preprocessed          [car, drive, slow]   \n\n                                                                            2  \ntext                                 The bike ride very fast and erratically!  \ntext_chat_conversion                 The bike ride very fast and erratically!  \ncorrect_spellings                     The bike ride very fast and erratically  \ntext_punctation_remove                The bike ride very fast and erratically  \ntext_lower                            the bike ride very fast and erratically  \ntext_stopwords_removal                             bike ride fast erratically  \ntext_stemmed                                             bike ride fast errat  \ntext_preprocessed                                  bike ride fast erratically  \ntext_lemmatized_with_pos              The bike ride very fast and erratically  \ntext_tokenize               [The, bike, ride, very, fast, and, erratically...  \ntext_tokenize_preprocessed                    [bike, ride, fast, erratically]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>text</th>\n      <td>The cars drive, fast and erratically</td>\n      <td>the car drive slow?</td>\n      <td>The bike ride very fast and erratically!</td>\n    </tr>\n    <tr>\n      <th>text_chat_conversion</th>\n      <td>The cars drive, fast and erratically</td>\n      <td>the car drive slow?</td>\n      <td>The bike ride very fast and erratically!</td>\n    </tr>\n    <tr>\n      <th>correct_spellings</th>\n      <td>The cars drive fast and erratically</td>\n      <td>the car drive slow</td>\n      <td>The bike ride very fast and erratically</td>\n    </tr>\n    <tr>\n      <th>text_punctation_remove</th>\n      <td>The cars drive fast and erratically</td>\n      <td>the car drive slow</td>\n      <td>The bike ride very fast and erratically</td>\n    </tr>\n    <tr>\n      <th>text_lower</th>\n      <td>the cars drive fast and erratically</td>\n      <td>the car drive slow</td>\n      <td>the bike ride very fast and erratically</td>\n    </tr>\n    <tr>\n      <th>text_stopwords_removal</th>\n      <td>cars drive fast erratically</td>\n      <td>car drive slow</td>\n      <td>bike ride fast erratically</td>\n    </tr>\n    <tr>\n      <th>text_stemmed</th>\n      <td>car drive fast errat</td>\n      <td>car drive slow</td>\n      <td>bike ride fast errat</td>\n    </tr>\n    <tr>\n      <th>text_preprocessed</th>\n      <td>car drive fast erratically</td>\n      <td>car drive slow</td>\n      <td>bike ride fast erratically</td>\n    </tr>\n    <tr>\n      <th>text_lemmatized_with_pos</th>\n      <td>The car drive fast and erratically</td>\n      <td>the car drive slow</td>\n      <td>The bike ride very fast and erratically</td>\n    </tr>\n    <tr>\n      <th>text_tokenize</th>\n      <td>[The, cars, drive, ,, fast, and, erratically]</td>\n      <td>[the, car, drive, slow, ?]</td>\n      <td>[The, bike, ride, very, fast, and, erratically...</td>\n    </tr>\n    <tr>\n      <th>text_tokenize_preprocessed</th>\n      <td>[car, drive, fast, erratically]</td>\n      <td>[car, drive, slow]</td>\n      <td>[bike, ride, fast, erratically]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:15.122056300Z",
     "start_time": "2023-05-04T13:14:15.071397500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ANALIZA DANYCH\n",
    "\n",
    "## Bag of Words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bike', 'car', 'drive', 'erratically', 'fast', 'ride', 'slow']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "vectorizer.fit(df[\"text_preprocessed\"])\n",
    "print(sorted(vectorizer.vocabulary_))\n",
    "vector = vectorizer.transform(df[\"text_preprocessed\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:19.509620600Z",
     "start_time": "2023-05-04T13:14:19.493333300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 1 0 0]\n",
      " [0 1 1 0 0 0 1]\n",
      " [1 0 0 1 1 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "   bike  car  drive  erratically  fast  ride  slow\n0     0    1      1            1     1     0     0\n1     0    1      1            0     0     0     1\n2     1    0      0            1     1     1     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bike</th>\n      <th>car</th>\n      <th>drive</th>\n      <th>erratically</th>\n      <th>fast</th>\n      <th>ride</th>\n      <th>slow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vector.toarray())\n",
    "pd.DataFrame(vector.toarray(),columns=sorted(vectorizer.vocabulary_))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:24.348475800Z",
     "start_time": "2023-05-04T13:14:24.333020500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'and', 'bike', 'car', 'cars', 'drive', 'erratically', 'fast', 'ride', 'slow', 'the', 'very']\n"
     ]
    }
   ],
   "source": [
    "vectorizer.fit(df[\"text_punctation_remove\"])\n",
    "print(sorted(vectorizer.vocabulary_))\n",
    "vector = vectorizer.transform(df[\"text_punctation_remove\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:31.016097700Z",
     "start_time": "2023-05-04T13:14:30.984973Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 1 1 1 1 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 1 1 0]\n",
      " [1 1 1 0 0 0 1 1 1 0 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "   The  and  bike  car  cars  drive  erratically  fast  ride  slow  the  very\n0    1    1     0    0     1      1            1     1     0     0    0     0\n1    0    0     0    1     0      1            0     0     0     1    1     0\n2    1    1     1    0     0      0            1     1     1     0    0     1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>The</th>\n      <th>and</th>\n      <th>bike</th>\n      <th>car</th>\n      <th>cars</th>\n      <th>drive</th>\n      <th>erratically</th>\n      <th>fast</th>\n      <th>ride</th>\n      <th>slow</th>\n      <th>the</th>\n      <th>very</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vector.toarray())\n",
    "pd.DataFrame(vector.toarray(),columns=sorted(vectorizer.vocabulary_))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:14:34.245499600Z",
     "start_time": "2023-05-04T13:14:34.211306800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "        and      bike       car      cars     drive  erratically      fast  \\\n0  0.397402  0.000000  0.000000  0.522535  0.397402     0.397402  0.397402   \n1  0.000000  0.000000  0.584483  0.000000  0.444514     0.000000  0.000000   \n2  0.337295  0.443503  0.000000  0.000000  0.000000     0.337295  0.337295   \n\n       ride      slow       the      very  \n0  0.000000  0.000000  0.308618  0.000000  \n1  0.000000  0.584483  0.345205  0.000000  \n2  0.443503  0.000000  0.261940  0.443503  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>and</th>\n      <th>bike</th>\n      <th>car</th>\n      <th>cars</th>\n      <th>drive</th>\n      <th>erratically</th>\n      <th>fast</th>\n      <th>ride</th>\n      <th>slow</th>\n      <th>the</th>\n      <th>very</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.397402</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.522535</td>\n      <td>0.397402</td>\n      <td>0.397402</td>\n      <td>0.397402</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.308618</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.584483</td>\n      <td>0.000000</td>\n      <td>0.444514</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.584483</td>\n      <td>0.345205</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.337295</td>\n      <td>0.443503</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.337295</td>\n      <td>0.337295</td>\n      <td>0.443503</td>\n      <td>0.000000</td>\n      <td>0.261940</td>\n      <td>0.443503</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df[\"text_punctation_remove\"])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df_one = pd.DataFrame(denselist, columns=feature_names)\n",
    "df_one"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:20:20.529363900Z",
     "start_time": "2023-05-04T13:20:20.491566Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "       bike       car     drive  erratically      fast      ride      slow\n0  0.000000  0.500000  0.500000     0.500000  0.500000  0.000000  0.000000\n1  0.000000  0.517856  0.517856     0.000000  0.000000  0.000000  0.680919\n2  0.562829  0.000000  0.000000     0.428046  0.428046  0.562829  0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bike</th>\n      <th>car</th>\n      <th>drive</th>\n      <th>erratically</th>\n      <th>fast</th>\n      <th>ride</th>\n      <th>slow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.517856</td>\n      <td>0.517856</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.680919</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.562829</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.428046</td>\n      <td>0.428046</td>\n      <td>0.562829</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df[\"text_preprocessed\"])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df_one = pd.DataFrame(denselist, columns=feature_names)\n",
    "df_one"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:17:25.914619400Z",
     "start_time": "2023-05-04T13:17:25.863619200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Podobieństwo Cosinusów\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a matrix to represent the corpus\n",
    "X = CountVectorizer().fit_transform(df['text_preprocessed']).toarray()\n",
    "\n",
    "cos = cosine_similarity([X[0,:],X[1,:],X[2,:]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:14:52.742170100Z",
     "start_time": "2023-05-04T14:14:52.734983700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 0.57735027, 0.5       ],\n       [0.57735027, 1.        , 0.        ],\n       [0.5       , 0.        , 1.        ]])"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:14:56.353959500Z",
     "start_time": "2023-05-04T14:14:56.344961800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
