{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import TweetTokenizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from pymongo import MongoClient\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "from GatherData.config import PASS, LOGIN\n",
    "\n",
    "import certifi\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import openpyxl\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 0\n",
    "## Organize variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "chat_words_str = \"\"\"\n",
    "DM=Direct message\n",
    "CT=Cuttweet\n",
    "RT=Retweet\n",
    "PRT=Partial retweet\n",
    "MT=Modified tweet\n",
    "PRT=Please retweet\n",
    "HT=Hat tip\n",
    "CC=Carbon-copy\n",
    "CX=Correction\n",
    "EM=Email Marketing\n",
    "SEO=Search Engine Optimization\n",
    "SROI=Social Return on Investment\n",
    "SN=Social Network\n",
    "YT=YouTube\n",
    "UGC=User-Generated Content\n",
    "SMO=Social Media Optimization\n",
    "FB=Facebook\n",
    "LI=LinkedIn\n",
    "SM=Social Media\n",
    "SMM=Social Media Marketing\n",
    "EZine=Electronic Magazine\n",
    "BGD=Background\n",
    "CD9=Code 9, parents are around\n",
    "BTW=By the way\n",
    "AB=About\n",
    "ABT=About\n",
    "DD=Dear daughter\n",
    "AFAIK=far as I know\n",
    "AYFKMWTS=Are you f—ing kidding me with this s—?\n",
    "BR=Best regards\n",
    "CHK=Check\n",
    "CUL8R=See you later\n",
    "DP=used to mean “profile pic”\n",
    "FML=F— my life\n",
    "FUBAR=F—ed up beyond all repair (slang from the US Military)\n",
    "BBFN=Bye for now\n",
    "B4=Before\n",
    "DS=Dear son\n",
    "FF=Follow Friday\n",
    "EMA=Email address\n",
    "DYK=Do you know\n",
    "F2F=Face to face\n",
    "FTF=Face to face\n",
    "HAGN=Have a good night\n",
    "DF=Dear fiancé\n",
    "DAM=Don’t annoy me\n",
    "FFS=For F—‘s Sake\n",
    "EM=Email\n",
    "EML=Email\n",
    "FOTD=Find of the day\n",
    "FTW=For the win, F— the world\n",
    "FWIW=For what it’s worth\n",
    "HTH=Hope that helps\n",
    "GMAFB=Give me a f—ing break\n",
    "HAND=Have a nice day\n",
    "ICYMI=In case you missed it\n",
    "GTFOOH=Get the f— out of here\n",
    "GTS=Guess the song\n",
    "HOTD=Headline of the day\n",
    "IIRC=If I remember correctly\n",
    "KYSO=Knock your socks off\n",
    "KK=Kewl kewl, or ok, got it\n",
    "HT=Head through\n",
    "IC=I see\n",
    "IDK=I don’t know\n",
    "LHH=hella hard\n",
    "ZOMG=OMG to the max\n",
    "IMHO=In my humble opinion\n",
    "NFW=No f—ing way\n",
    "ORLY=Oh, really?\n",
    "YOYO=You’re on your own\n",
    "LMAO=Laughing my ass off\n",
    "IRL=In real life\n",
    "JK=Just kidding\n",
    "JV=Joint venture\n",
    "LO=Little One\n",
    "LOL=Laugh out loud\n",
    "MM=Music Monday\n",
    "LMK=Let me know\n",
    "TY=Thank you\n",
    "SRS=Serious\n",
    "STF=Shut the f—\n",
    "STFU=Shut the f— up!\n",
    "TL=Timeline\n",
    "TYIA=Thank you in advance\n",
    "TT=Trending topic\n",
    "TYVW=Thank you very much\n",
    "BRB=Be Right Back\n",
    "AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "B4N=Bye For Now\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=ILU: I Love You\n",
    "IMHO=In My Honest Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laugh My A.. Off\n",
    "LOL=Laughing Out Loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "SFW=Safe for work\n",
    "TY=Thank you\n",
    "TMB=Tweet me back\n",
    "BRB=Be Right Back\n",
    "IMO=In My Opinion\n",
    "RLRT=Real-life re-tweet, a close cousin to OH\n",
    "OOMF=One of my friends/followers\n",
    "NTS=Note to self\n",
    "RTFM=Read the f—ing manual\n",
    "SNAFU=Situation normal, all f—ed up (slang from the US Military)\n",
    "RLRT=Real-life re-tweet, a close cousin to OH\n",
    "SMH=Shaking my head\n",
    "STFW=Search the f—ing web!\n",
    "TFTT=Thanks for this tweet\n",
    "SOB=Son of a B—-\n",
    "TFTF=Thanks for the follow\n",
    "PRW=Parents Are Watching\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher\n",
    "\"\"\"\n",
    "# Thanks : https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "EMOTICONS = {\n",
    "    u\":‑\\)\": \"Happy face or smiley\",\n",
    "    u\":\\)\": \"Happy face or smiley\",\n",
    "    u\":-\\]\": \"Happy face or smiley\",\n",
    "    u\":\\]\": \"Happy face or smiley\",\n",
    "    u\":-3\": \"Happy face smiley\",\n",
    "    u\":3\": \"Happy face smiley\",\n",
    "    u\":->\": \"Happy face smiley\",\n",
    "    u\":>\": \"Happy face smiley\",\n",
    "    u\"8-\\)\": \"Happy face smiley\",\n",
    "    u\":o\\)\": \"Happy face smiley\",\n",
    "    u\":-\\}\": \"Happy face smiley\",\n",
    "    u\":\\}\": \"Happy face smiley\",\n",
    "    u\":-\\)\": \"Happy face smiley\",\n",
    "    u\":c\\)\": \"Happy face smiley\",\n",
    "    u\":\\^\\)\": \"Happy face smiley\",\n",
    "    u\"=\\]\": \"Happy face smiley\",\n",
    "    u\"=\\)\": \"Happy face smiley\",\n",
    "    u\":‑D\": \"Laughing, big grin or laugh with glasses\",\n",
    "    u\":D\": \"Laughing, big grin or laugh with glasses\",\n",
    "    u\"8‑D\": \"Laughing, big grin or laugh with glasses\",\n",
    "    u\"8D\": \"Laughing, big grin or laugh with glasses\",\n",
    "    u\"X‑D\": \"Laughing, big grin or laugh with glasses\",\n",
    "    u\"XD\": \"Laughing, big grin or laugh with glasses\",\n",
    "    u\"=D\": \"Laughing, big grin or laugh with glasses\",\n",
    "    u\"=3\": \"Laughing, big grin or laugh with glasses\",\n",
    "    u\"B\\^D\": \"Laughing, big grin or laugh with glasses\",\n",
    "    u\":-\\)\\)\": \"Very happy\",\n",
    "    u\":‑\\(\": \"Frown, sad, andry or pouting\",\n",
    "    u\":-\\(\": \"Frown, sad, andry or pouting\",\n",
    "    u\":\\(\": \"Frown, sad, andry or pouting\",\n",
    "    u\":‑c\": \"Frown, sad, andry or pouting\",\n",
    "    u\":c\": \"Frown, sad, andry or pouting\",\n",
    "    u\":‑<\": \"Frown, sad, andry or pouting\",\n",
    "    u\":<\": \"Frown, sad, andry or pouting\",\n",
    "    u\":‑\\[\": \"Frown, sad, andry or pouting\",\n",
    "    u\":\\[\": \"Frown, sad, andry or pouting\",\n",
    "    u\":-\\|\\|\": \"Frown, sad, andry or pouting\",\n",
    "    u\">:\\[\": \"Frown, sad, andry or pouting\",\n",
    "    u\":\\{\": \"Frown, sad, andry or pouting\",\n",
    "    u\":@\": \"Frown, sad, andry or pouting\",\n",
    "    u\">:\\(\": \"Frown, sad, andry or pouting\",\n",
    "    u\":'‑\\(\": \"Crying\",\n",
    "    u\":'\\(\": \"Crying\",\n",
    "    u\":'‑\\)\": \"Tears of happiness\",\n",
    "    u\":'\\)\": \"Tears of happiness\",\n",
    "    u\"D‑':\": \"Horror\",\n",
    "    u\"D:<\": \"Disgust\",\n",
    "    u\"D:\": \"Sadness\",\n",
    "    u\"D8\": \"Great dismay\",\n",
    "    u\"D;\": \"Great dismay\",\n",
    "    u\"D=\": \"Great dismay\",\n",
    "    u\"DX\": \"Great dismay\",\n",
    "    u\":‑O\": \"Surprise\",\n",
    "    u\":O\": \"Surprise\",\n",
    "    u\":‑o\": \"Surprise\",\n",
    "    u\":o\": \"Surprise\",\n",
    "    u\":-0\": \"Shock\",\n",
    "    u\"8‑0\": \"Yawn\",\n",
    "    u\">:O\": \"Yawn\",\n",
    "    u\":-\\*\": \"Kiss\",\n",
    "    u\":\\*\": \"Kiss\",\n",
    "    u\":X\": \"Kiss\",\n",
    "    u\";‑\\)\": \"Wink or smirk\",\n",
    "    u\";\\)\": \"Wink or smirk\",\n",
    "    u\"\\*-\\)\": \"Wink or smirk\",\n",
    "    u\"\\*\\)\": \"Wink or smirk\",\n",
    "    u\";‑\\]\": \"Wink or smirk\",\n",
    "    u\";\\]\": \"Wink or smirk\",\n",
    "    u\";\\^\\)\": \"Wink or smirk\",\n",
    "    u\":‑,\": \"Wink or smirk\",\n",
    "    u\";D\": \"Wink or smirk\",\n",
    "    u\":‑P\": \"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":P\": \"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"X‑P\": \"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"XP\": \"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":‑Þ\": \"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":Þ\": \"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":b\": \"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"d:\": \"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"=p\": \"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\">:P\": \"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":‑/\": \"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":/\": \"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":-[.]\": \"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\">:[(\\\\\\)]\": \"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\">:/\": \"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":[(\\\\\\)]\": \"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=/\": \"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=[(\\\\\\)]\": \"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":L\": \"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=L\": \"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":S\": \"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":‑\\|\": \"Straight face\",\n",
    "    u\":\\|\": \"Straight face\",\n",
    "    u\":$\": \"Embarrassed or blushing\",\n",
    "    u\":‑x\": \"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":x\": \"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":‑#\": \"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":#\": \"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":‑&\": \"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":&\": \"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\"O:‑\\)\": \"Angel, saint or innocent\",\n",
    "    u\"O:\\)\": \"Angel, saint or innocent\",\n",
    "    u\"0:‑3\": \"Angel, saint or innocent\",\n",
    "    u\"0:3\": \"Angel, saint or innocent\",\n",
    "    u\"0:‑\\)\": \"Angel, saint or innocent\",\n",
    "    u\"0:\\)\": \"Angel, saint or innocent\",\n",
    "    u\":‑b\": \"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"0;\\^\\)\": \"Angel, saint or innocent\",\n",
    "    u\">:‑\\)\": \"Evil or devilish\",\n",
    "    u\">:\\)\": \"Evil or devilish\",\n",
    "    u\"\\}:‑\\)\": \"Evil or devilish\",\n",
    "    u\"\\}:\\)\": \"Evil or devilish\",\n",
    "    u\"3:‑\\)\": \"Evil or devilish\",\n",
    "    u\"3:\\)\": \"Evil or devilish\",\n",
    "    u\">;\\)\": \"Evil or devilish\",\n",
    "    u\"\\|;‑\\)\": \"Cool\",\n",
    "    u\"\\|‑O\": \"Bored\",\n",
    "    u\":‑J\": \"Tongue-in-cheek\",\n",
    "    u\"#‑\\)\": \"Party all night\",\n",
    "    u\"%‑\\)\": \"Drunk or confused\",\n",
    "    u\"%\\)\": \"Drunk or confused\",\n",
    "    u\":-###..\": \"Being sick\",\n",
    "    u\":###..\": \"Being sick\",\n",
    "    u\"<:‑\\|\": \"Dump\",\n",
    "    u\"\\(>_<\\)\": \"Troubled\",\n",
    "    u\"\\(>_<\\)>\": \"Troubled\",\n",
    "    u\"\\(';'\\)\": \"Baby\",\n",
    "    u\"\\(\\^\\^>``\": \"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(\\^_\\^;\\)\": \"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(-_-;\\)\": \"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(~_~;\\) \\(・\\.・;\\)\": \"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(-_-\\)zzz\": \"Sleeping\",\n",
    "    u\"\\(\\^_-\\)\": \"Wink\",\n",
    "    u\"\\(\\(\\+_\\+\\)\\)\": \"Confused\",\n",
    "    u\"\\(\\+o\\+\\)\": \"Confused\",\n",
    "    u\"\\(o\\|o\\)\": \"Ultraman\",\n",
    "    u\"\\^_\\^\": \"Joyful\",\n",
    "    u\"\\(\\^_\\^\\)/\": \"Joyful\",\n",
    "    u\"\\(\\^O\\^\\)／\": \"Joyful\",\n",
    "    u\"\\(\\^o\\^\\)／\": \"Joyful\",\n",
    "    u\"\\(__\\)\": \"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"_\\(\\._\\.\\)_\": \"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"<\\(_ _\\)>\": \"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"<m\\(__\\)m>\": \"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"m\\(__\\)m\": \"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"m\\(_ _\\)m\": \"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"\\('_'\\)\": \"Sad or Crying\",\n",
    "    u\"\\(/_;\\)\": \"Sad or Crying\",\n",
    "    u\"\\(T_T\\) \\(;_;\\)\": \"Sad or Crying\",\n",
    "    u\"\\(;_;\": \"Sad of Crying\",\n",
    "    u\"\\(;_:\\)\": \"Sad or Crying\",\n",
    "    u\"\\(;O;\\)\": \"Sad or Crying\",\n",
    "    u\"\\(:_;\\)\": \"Sad or Crying\",\n",
    "    u\"\\(ToT\\)\": \"Sad or Crying\",\n",
    "    u\";_;\": \"Sad or Crying\",\n",
    "    u\";-;\": \"Sad or Crying\",\n",
    "    u\";n;\": \"Sad or Crying\",\n",
    "    u\";;\": \"Sad or Crying\",\n",
    "    u\"Q\\.Q\": \"Sad or Crying\",\n",
    "    u\"T\\.T\": \"Sad or Crying\",\n",
    "    u\"QQ\": \"Sad or Crying\",\n",
    "    u\"Q_Q\": \"Sad or Crying\",\n",
    "    u\"\\(-\\.-\\)\": \"Shame\",\n",
    "    u\"\\(-_-\\)\": \"Shame\",\n",
    "    u\"\\(一一\\)\": \"Shame\",\n",
    "    u\"\\(；一_一\\)\": \"Shame\",\n",
    "    u\"\\(=_=\\)\": \"Tired\",\n",
    "    u\"\\(=\\^\\·\\^=\\)\": \"cat\",\n",
    "    u\"\\(=\\^\\·\\·\\^=\\)\": \"cat\",\n",
    "    u\"=_\\^=\t\": \"cat\",\n",
    "    u\"\\(\\.\\.\\)\": \"Looking down\",\n",
    "    u\"\\(\\._\\.\\)\": \"Looking down\",\n",
    "    u\"\\^m\\^\": \"Giggling with hand covering mouth\",\n",
    "    u\"\\(\\・\\・?\": \"Confusion\",\n",
    "    u\"\\(?_?\\)\": \"Confusion\",\n",
    "    u\">\\^_\\^<\": \"Normal Laugh\",\n",
    "    u\"<\\^!\\^>\": \"Normal Laugh\",\n",
    "    u\"\\^/\\^\": \"Normal Laugh\",\n",
    "    u\"\\（\\*\\^_\\^\\*）\": \"Normal Laugh\",\n",
    "    u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\": \"Normal Laugh\",\n",
    "    u\"\\(^\\^\\)\": \"Normal Laugh\",\n",
    "    u\"\\(\\^\\.\\^\\)\": \"Normal Laugh\",\n",
    "    u\"\\(\\^_\\^\\.\\)\": \"Normal Laugh\",\n",
    "    u\"\\(\\^_\\^\\)\": \"Normal Laugh\",\n",
    "    u\"\\(\\^\\^\\)\": \"Normal Laugh\",\n",
    "    u\"\\(\\^J\\^\\)\": \"Normal Laugh\",\n",
    "    u\"\\(\\*\\^\\.\\^\\*\\)\": \"Normal Laugh\",\n",
    "    u\"\\(\\^—\\^\\）\": \"Normal Laugh\",\n",
    "    u\"\\(#\\^\\.\\^#\\)\": \"Normal Laugh\",\n",
    "    u\"\\（\\^—\\^\\）\": \"Waving\",\n",
    "    u\"\\(;_;\\)/~~~\": \"Waving\",\n",
    "    u\"\\(\\^\\.\\^\\)/~~~\": \"Waving\",\n",
    "    u\"\\(-_-\\)/~~~ \\($\\·\\·\\)/~~~\": \"Waving\",\n",
    "    u\"\\(T_T\\)/~~~\": \"Waving\",\n",
    "    u\"\\(ToT\\)/~~~\": \"Waving\",\n",
    "    u\"\\(\\*\\^0\\^\\*\\)\": \"Excited\",\n",
    "    u\"\\(\\*_\\*\\)\": \"Amazed\",\n",
    "    u\"\\(\\*_\\*;\": \"Amazed\",\n",
    "    u\"\\(\\+_\\+\\) \\(@_@\\)\": \"Amazed\",\n",
    "    u\"\\(\\*\\^\\^\\)v\": \"Laughing,Cheerful\",\n",
    "    u\"\\(\\^_\\^\\)v\": \"Laughing,Cheerful\",\n",
    "    u\"\\(\\(d[-_-]b\\)\\)\": \"Headphones,Listening to music\",\n",
    "    u'\\(-\"-\\)': \"Worried\",\n",
    "    u\"\\(ーー;\\)\": \"Worried\",\n",
    "    u\"\\(\\^0_0\\^\\)\": \"Eyeglasses\",\n",
    "    u\"\\(\\＾ｖ\\＾\\)\": \"Happy\",\n",
    "    u\"\\(\\＾ｕ\\＾\\)\": \"Happy\",\n",
    "    u\"\\(\\^\\)o\\(\\^\\)\": \"Happy\",\n",
    "    u\"\\(\\^O\\^\\)\": \"Happy\",\n",
    "    u\"\\(\\^o\\^\\)\": \"Happy\",\n",
    "    u\"\\)\\^o\\^\\(\": \"Happy\",\n",
    "    u\":O o_O\": \"Surprised\",\n",
    "    u\"o_0\": \"Surprised\",\n",
    "    u\"o\\.O\": \"Surpised\",\n",
    "    u\"\\(o\\.o\\)\": \"Surprised\",\n",
    "    u\"oO\": \"Surprised\",\n",
    "    u\"\\(\\*￣m￣\\)\": \"Dissatisfied\",\n",
    "    u\"\\(‘A`\\)\": \"Snubbed or Deflated\"\n",
    "}\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1\n",
    "## Get the data from MongoDB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Loading data from mongoDB\n",
    "ca = certifi.where()\n",
    "\n",
    "client = MongoClient(f\"mongodb+srv://{LOGIN}:{PASS}@cluster0.psdqkii.mongodb.net/Twitter\", tlsCAFile=ca)\n",
    "db = client[\"Ukraine_war\"]\n",
    "collection = db[\"Putin\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "query = {}\n",
    "cursor = collection.find(query)\n",
    "df = pd.DataFrame(list(cursor))\n",
    "# Drop duplicates by id to only get different text data\n",
    "df.drop_duplicates(subset=[\"id\"], inplace=True)\n",
    "df.drop_duplicates(subset=[\"text\"], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "                        _id          created_at          id  \\\n0  6422f409fb4cd482b31ca111 2010-01-01 22:32:58  7280962909   \n1  6422f409fb4cd482b31ca120 2010-01-01 21:10:07  7279023057   \n2  6422f409fb4cd482b31ca13d 2010-01-01 18:37:17  7275456663   \n3  6422f409fb4cd482b31ca156 2010-01-01 15:46:21  7271667409   \n4  6422f409fb4cd482b31ca109 2010-01-01 23:04:32  7281699376   \n\n                                                text     screen_name  \\\n0            Yes i do stupid am just not putin the @  jak3_dat_ni66a   \n1  RT @DaRealAlBundie @Adriana_xo & @Tattoo_CrAzY...    Tattoo_CrAzY   \n2  @loserkid745 yo dm me ur num and il text u whe...   nephew_tweets   \n3  Absolutely loving Medvedev and Putin's cartoon...     JulianMarch   \n4  Medvedev and Putin dance in New Year cartoon d...     neurodrive1   \n\n               name  retweet_count  like_count  quote_count view_count  \\\n0              rome              0           0            0       None   \n1        Mr. TaTtOo              0           0            0       None   \n2  lathon hernandez              0           0            0       None   \n3      Julian March              0           0            0       None   \n4             Gloop              0           0            0       None   \n\n         user_created  user_favourites_count  user_followers_count  \\\n0 2009-12-30 01:58:03                      2                    83   \n1 2009-08-25 16:05:08                     50                  1456   \n2 2009-05-18 18:52:35                      2                    27   \n3 2007-08-07 19:36:21                    522                  3184   \n4 2009-10-15 08:40:30                      9                   673   \n\n   user_friends_count  user_statuses_count  verified  topic  \n0                 137                 2438     False  Putin  \n1                 960                47738     False  Putin  \n2                  30                  773     False  Putin  \n3                 719                 6638      True  Putin  \n4                  37                85931     False  Putin  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>text</th>\n      <th>screen_name</th>\n      <th>name</th>\n      <th>retweet_count</th>\n      <th>like_count</th>\n      <th>quote_count</th>\n      <th>view_count</th>\n      <th>user_created</th>\n      <th>user_favourites_count</th>\n      <th>user_followers_count</th>\n      <th>user_friends_count</th>\n      <th>user_statuses_count</th>\n      <th>verified</th>\n      <th>topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6422f409fb4cd482b31ca111</td>\n      <td>2010-01-01 22:32:58</td>\n      <td>7280962909</td>\n      <td>Yes i do stupid am just not putin the @</td>\n      <td>jak3_dat_ni66a</td>\n      <td>rome</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2009-12-30 01:58:03</td>\n      <td>2</td>\n      <td>83</td>\n      <td>137</td>\n      <td>2438</td>\n      <td>False</td>\n      <td>Putin</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6422f409fb4cd482b31ca120</td>\n      <td>2010-01-01 21:10:07</td>\n      <td>7279023057</td>\n      <td>RT @DaRealAlBundie @Adriana_xo &amp; @Tattoo_CrAzY...</td>\n      <td>Tattoo_CrAzY</td>\n      <td>Mr. TaTtOo</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2009-08-25 16:05:08</td>\n      <td>50</td>\n      <td>1456</td>\n      <td>960</td>\n      <td>47738</td>\n      <td>False</td>\n      <td>Putin</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6422f409fb4cd482b31ca13d</td>\n      <td>2010-01-01 18:37:17</td>\n      <td>7275456663</td>\n      <td>@loserkid745 yo dm me ur num and il text u whe...</td>\n      <td>nephew_tweets</td>\n      <td>lathon hernandez</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2009-05-18 18:52:35</td>\n      <td>2</td>\n      <td>27</td>\n      <td>30</td>\n      <td>773</td>\n      <td>False</td>\n      <td>Putin</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6422f409fb4cd482b31ca156</td>\n      <td>2010-01-01 15:46:21</td>\n      <td>7271667409</td>\n      <td>Absolutely loving Medvedev and Putin's cartoon...</td>\n      <td>JulianMarch</td>\n      <td>Julian March</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2007-08-07 19:36:21</td>\n      <td>522</td>\n      <td>3184</td>\n      <td>719</td>\n      <td>6638</td>\n      <td>True</td>\n      <td>Putin</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6422f409fb4cd482b31ca109</td>\n      <td>2010-01-01 23:04:32</td>\n      <td>7281699376</td>\n      <td>Medvedev and Putin dance in New Year cartoon d...</td>\n      <td>neurodrive1</td>\n      <td>Gloop</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2009-10-15 08:40:30</td>\n      <td>9</td>\n      <td>673</td>\n      <td>37</td>\n      <td>85931</td>\n      <td>False</td>\n      <td>Putin</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2\n",
    "## Preproces text data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# emoji.demojize(df_text[2]) idea for later\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "\n",
    "# convert chat shortcuts\n",
    "\n",
    "chat_words_map_dict = {}\n",
    "chat_words_list = []\n",
    "spell = SpellChecker()\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z]+\"\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "for line in chat_words_str.split(\"\\n\"):\n",
    "    if line != \"\":\n",
    "        cw = line.split(\"=\")[0]\n",
    "        cw_expanded = line.split(\"=\")[1]\n",
    "        chat_words_list.append(cw)\n",
    "        chat_words_map_dict[cw] = cw_expanded\n",
    "chat_words_list = set(chat_words_list)\n",
    "\n",
    "\n",
    "def chat_words_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words_list:\n",
    "            new_text.append(chat_words_map_dict[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def preprocess(text, stem=False):\n",
    "    text = \" \".join(chat_words_conversion(tweet_tokenizer.tokenize(text)))\n",
    "    text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(lemmatizer.lemmatize(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    if \"n\" in tokens:\n",
    "        print(tokens)\n",
    "    return \" \".join(tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[55], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpreprocessed_text\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4661\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4662\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4663\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4666\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4667\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4668\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4669\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4670\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4769\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4770\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[0;32m   1122\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[1;32m-> 1123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1172\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1173\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m-> 1174\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1175\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1176\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1178\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1181\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1182\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[55], line 1\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpreprocessed_text\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mpreprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[1;32mIn[54], line 43\u001B[0m, in \u001B[0;36mpreprocess\u001B[1;34m(text, stem)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreprocess\u001B[39m(text, stem\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m---> 43\u001B[0m     text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[43mchat_words_conversion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtweet_tokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     44\u001B[0m     text \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(text_cleaning_re, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mstr\u001B[39m(text)\u001B[38;5;241m.\u001B[39mlower())\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m     45\u001B[0m     tokens \u001B[38;5;241m=\u001B[39m []\n",
      "Cell \u001B[1;32mIn[54], line 24\u001B[0m, in \u001B[0;36mchat_words_conversion\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mchat_words_conversion\u001B[39m(text):\n\u001B[0;32m     23\u001B[0m     new_text \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 24\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m():\n\u001B[0;32m     25\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m w\u001B[38;5;241m.\u001B[39mupper() \u001B[38;5;129;01min\u001B[39;00m chat_words_list:\n\u001B[0;32m     26\u001B[0m             new_text\u001B[38;5;241m.\u001B[39mappend(chat_words_map_dict[w\u001B[38;5;241m.\u001B[39mupper()])\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "df[\"preprocessed_text\"] = df[\"text\"].apply(lambda x: preprocess(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "                             _id                created_at  \\\n0       637fe25c077f062d5f873b5e 2022-11-24 19:29:59+00:00   \n1       637fe25c077f062d5f873b61 2022-11-24 19:25:37+00:00   \n2       637fe25c077f062d5f873b5c 2022-11-24 20:49:24+00:00   \n3       637fe25c077f062d5f873b63 2022-11-24 19:21:56+00:00   \n4       637fe25c077f062d5f873b5b 2022-11-24 21:03:18+00:00   \n...                          ...                       ...   \n100896  6387ca582999ab3d122ba242 2022-11-30 19:38:35+00:00   \n100897  6387ca582999ab3d122ba244 2022-11-30 19:38:35+00:00   \n100898  6387ca582999ab3d122ba25d 2022-11-30 19:38:34+00:00   \n100899  6387ca582999ab3d122ba271 2022-11-30 19:38:33+00:00   \n100900  641f0e30b2405c8d0ebd168b 2023-03-25 15:06:30+00:00   \n\n                         id  \\\n0       1595862310953820163   \n1       1595861213409599488   \n2       1595882299593211904   \n3       1595860284811378696   \n4       1595885797768859648   \n...                     ...   \n100896  1598038801859088384   \n100897  1598038801443860480   \n100898  1598038797916450816   \n100899  1598038795160412160   \n100900  1639644934625021953   \n\n                                                     text  retweet_count  \\\n0       Unbelievable! Was this interview supposed to p...              1   \n1        The girls really let themselves down☹#TheOneShow              0   \n2       I found the chaos of tonight's #TheOneShow hil...              0   \n3       Is #RonanKeating putting on that #accent?? #th...              0   \n4       #theoneshow Has all the Botox gone to Mel B's ...              0   \n...                                                   ...            ...   \n100896  That penalty is an absolute joke!! Terrible!! ...              0   \n100897  That is possibly one of the worst penalty deci...              0   \n100898              That's a terrible decision!!! #POLARG              0   \n100899  How in the world of holy fuck, is that a penal...              0   \n100900    #t5m2 Moje sny be like: https://t.co/LsWYQlY4kB              0   \n\n        favorite_count      hashtag screen_name       name  favourites_count  \\\n0                  8.0  #TheOneShow         NaN        NaN               NaN   \n1                  2.0  #TheOneShow         NaN        NaN               NaN   \n2                  0.0  #TheOneShow         NaN        NaN               NaN   \n3                  0.0  #TheOneShow         NaN        NaN               NaN   \n4                  1.0  #TheOneShow         NaN        NaN               NaN   \n...                ...          ...         ...        ...               ...   \n100896             0.0      #POLARG         NaN        NaN               NaN   \n100897             1.0      #POLARG         NaN        NaN               NaN   \n100898             4.0      #POLARG         NaN        NaN               NaN   \n100899             4.0      #POLARG         NaN        NaN               NaN   \n100900             NaN          NaN   EImierska  Emilianna             211.0   \n\n        friends_count  followers_count  statuses_count verified  \\\n0                 NaN              NaN             NaN      NaN   \n1                 NaN              NaN             NaN      NaN   \n2                 NaN              NaN             NaN      NaN   \n3                 NaN              NaN             NaN      NaN   \n4                 NaN              NaN             NaN      NaN   \n...               ...              ...             ...      ...   \n100896            NaN              NaN             NaN      NaN   \n100897            NaN              NaN             NaN      NaN   \n100898            NaN              NaN             NaN      NaN   \n100899            NaN              NaN             NaN      NaN   \n100900           64.0              1.0            83.0    False   \n\n           user_created_at  \n0                      NaT  \n1                      NaT  \n2                      NaT  \n3                      NaT  \n4                      NaT  \n...                    ...  \n100896                 NaT  \n100897                 NaT  \n100898                 NaT  \n100899                 NaT  \n100900 2021-07-29 17:45:05  \n\n[95557 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>text</th>\n      <th>retweet_count</th>\n      <th>favorite_count</th>\n      <th>hashtag</th>\n      <th>screen_name</th>\n      <th>name</th>\n      <th>favourites_count</th>\n      <th>friends_count</th>\n      <th>followers_count</th>\n      <th>statuses_count</th>\n      <th>verified</th>\n      <th>user_created_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>637fe25c077f062d5f873b5e</td>\n      <td>2022-11-24 19:29:59+00:00</td>\n      <td>1595862310953820163</td>\n      <td>Unbelievable! Was this interview supposed to p...</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>#TheOneShow</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>637fe25c077f062d5f873b61</td>\n      <td>2022-11-24 19:25:37+00:00</td>\n      <td>1595861213409599488</td>\n      <td>The girls really let themselves down☹#TheOneShow</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>#TheOneShow</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>637fe25c077f062d5f873b5c</td>\n      <td>2022-11-24 20:49:24+00:00</td>\n      <td>1595882299593211904</td>\n      <td>I found the chaos of tonight's #TheOneShow hil...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>#TheOneShow</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>637fe25c077f062d5f873b63</td>\n      <td>2022-11-24 19:21:56+00:00</td>\n      <td>1595860284811378696</td>\n      <td>Is #RonanKeating putting on that #accent?? #th...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>#TheOneShow</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>637fe25c077f062d5f873b5b</td>\n      <td>2022-11-24 21:03:18+00:00</td>\n      <td>1595885797768859648</td>\n      <td>#theoneshow Has all the Botox gone to Mel B's ...</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>#TheOneShow</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100896</th>\n      <td>6387ca582999ab3d122ba242</td>\n      <td>2022-11-30 19:38:35+00:00</td>\n      <td>1598038801859088384</td>\n      <td>That penalty is an absolute joke!! Terrible!! ...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>#POLARG</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>100897</th>\n      <td>6387ca582999ab3d122ba244</td>\n      <td>2022-11-30 19:38:35+00:00</td>\n      <td>1598038801443860480</td>\n      <td>That is possibly one of the worst penalty deci...</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>#POLARG</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>100898</th>\n      <td>6387ca582999ab3d122ba25d</td>\n      <td>2022-11-30 19:38:34+00:00</td>\n      <td>1598038797916450816</td>\n      <td>That's a terrible decision!!! #POLARG</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>#POLARG</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>100899</th>\n      <td>6387ca582999ab3d122ba271</td>\n      <td>2022-11-30 19:38:33+00:00</td>\n      <td>1598038795160412160</td>\n      <td>How in the world of holy fuck, is that a penal...</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>#POLARG</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>100900</th>\n      <td>641f0e30b2405c8d0ebd168b</td>\n      <td>2023-03-25 15:06:30+00:00</td>\n      <td>1639644934625021953</td>\n      <td>#t5m2 Moje sny be like: https://t.co/LsWYQlY4kB</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>EImierska</td>\n      <td>Emilianna</td>\n      <td>211.0</td>\n      <td>64.0</td>\n      <td>1.0</td>\n      <td>83.0</td>\n      <td>False</td>\n      <td>2021-07-29 17:45:05</td>\n    </tr>\n  </tbody>\n</table>\n<p>95557 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
